{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5060eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pyfaidx import Fasta\n",
    "import pandas as pd\n",
    "import torch\n",
    "from random import randrange, random\n",
    "import numpy as np\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a97b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_file = Path(\"/scratch/kyle/hyena-dna/data/hg38/hg38.ml.fa\")\n",
    "seqs = Fasta(str(fasta_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "421881e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    \"N\": 0,\n",
    "    \"A\": 1,\n",
    "    \"C\": 2,\n",
    "    \"G\": 3,\n",
    "    \"T\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9437e98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = list(\"\".join(str(seqs[chr_name][:]) for chr_name in seqs.keys()))\n",
    "ids = [vocab.get(c, 0) for c in seqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ad8d4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(ids):\n",
    "    counts = {}\n",
    "    for pair in zip(ids, ids[1:]):\n",
    "        if 0 not in pair: # refusing to merge N tokens\n",
    "            counts[pair] = counts.get(pair, 0) + 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cda2a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(ids, pair, idx):\n",
    "    newids = []\n",
    "    i = 0\n",
    "    while i < len(ids):\n",
    "        if i<len(ids)-1 and ids[i]==pair[0] and ids[i+1]==pair[1]:\n",
    "            newids.append(idx)\n",
    "            i+=2\n",
    "        else:\n",
    "            newids.append(ids[i])\n",
    "            i+=1\n",
    "    return newids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af9e09bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b983100",
   "metadata": {},
   "outputs": [],
   "source": [
    "merges = {} # List[Tuple[int, int], int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bbb15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                  | 0/4091 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(vocab), vocab_size)):\n",
    "    stats = get_stats(ids)\n",
    "    pair = max(stats, key=stats.get)\n",
    "    ids = merge(ids, pair, i)\n",
    "    merges[pair] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1fbb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_vocab = {v:k for k,v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3446dc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (p0, p1), idx in merges.items():\n",
    "    r_vocab[idx] = r_vocab[p0] + r_vocab[p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c3edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {v:k for k,v in r_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca589a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "merges = [(r_vocab[p0], r_vocab[p1]) for (p0, p1), _ in merges.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ed77db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(models.BPE(vocab=vocab, merges=merges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0690ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decoder = decoders.ByteLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c810cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(\"tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b90db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import PreTrainedTokenizerFast\n",
    "# tokenizer = PreTrainedTokenizerFast(tokenizer_object=tokenizer, unk_token=\"N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b04c358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer(\"NNATGGGGTATGAGCCC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b076d8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.decode([0, 0, 410, 64, 170], skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
